# Лабораторная работа №4. Анализ данных с помощью Dask и визуализация графов (DAG)

**Цель работы.** Получить практические навыки работы с библиотекой Dask для обработки больших массивов данных, не помещающихся в оперативную память, изучить принципы «ленивых вычислений» (lazy evaluation) и научиться визуализировать ориентированные ациклические графы (DAG).

**Инструментарий:**
*   Язык программирования: Python 3.
*   Среда выполнения: Google Colab или Jupyter Notebook (локально).
*   Библиотеки: `dask`, `pandas`, `graphviz`.

**Рабочий файл.** Результат выполнения работы сохранить в файл с именем `lab_04_variant_XX.ipynb` (где XX — номер вашего варианта).

---

## Задание 4.1. Анализ данных с помощью Dask

В этой части необходимо выполнить базовую предобработку и анализ большого датасета, используя Dask DataFrame API.

### 4.1.1. Настройка среды и рабочего каталога
Установите библиотеку Dask (если используете Colab) и подключите необходимые модули.

```python
# Установка Dask с полным набором зависимостей
!pip install "dask[complete]"

import sys
import os
import dask.dataframe as dd
from dask.diagnostics import ProgressBar
import pandas as pd

# Если работаете в Google Colab, подключите диск
from google.colab import drive
drive.mount('/content/drive')
```

### 4.1.2. Загрузка данных
Загрузите датасет, соответствующий вашему варианту (см. раздел "Варианты заданий").

```python
# Чтение CSV файла с помощью Dask
# Обратите внимание: данные не загружаются в память сразу
df = dd.read_csv('путь_к_вашему_файлу.csv')

# Просмотр структуры (метаданных)
df
```
*Обратите внимание на количество разделов (partitions) и типы данных.*

### 4.1.3. Проверка качества данных
Проведите анализ пропущенных значений. Поскольку Dask использует ленивые вычисления, для получения результата необходимо вызвать метод `.compute()`.

```python
# Подсчет пропущенных значений (построение графа вычислений)
missing_values = df.isnull().sum()

# Вычисление процента пропусков
mysize = df.index.size
missing_count = ((missing_values / mysize) * 100)

# Запуск вычислений с прогресс-баром
with ProgressBar():
    missing_count_percent = missing_count.compute()

print(missing_count_percent)
```

### 4.1.4. Очистка данных
Удалите столбцы, в которых содержится слишком много пропущенных значений (например, более 60%).

```python
# Фильтрация столбцов, где пропусков > 60%
columns_to_drop = missing_count_percent[missing_count_percent > 60].index
print("Удаляемые столбцы:", columns_to_drop)

# Удаление и фиксация результата
with ProgressBar():
    # .persist() сохраняет промежуточный результат в памяти кластера/воркера
    df_dropped = df.drop(columns_to_drop, axis=1).persist()
    print(df_dropped.head())
```

---

## Задание 4.2. Визуализация ориентированных ациклических графов (DAG)

Dask составляет граф выполнения задач перед тем, как начать вычисления. В этом задании необходимо визуализировать этот процесс.

### 4.2.1. Визуализация DAG с одним узлом
Создайте простую цепочку отложенных вычислений и визуализируйте её.

```python
import dask.delayed as delayed

def increment(i):
    return i + 1

def add(x, y):
    return x + y

# Создание отложенных объектов
x = delayed(increment)(1)
y = delayed(increment)(2)
z = delayed(add)(x, y)

# Визуализация графа
z.visualize()

# Получение результата
print(z.compute())
```

### 4.2.2. Визуализация сложного DAG
Постройте двухуровневый граф вычислений на основе списка данных.

```python
data = [1, 2, 3, 4, 5]

# Слой 1: Инкремент каждого элемента
layer1 = [delayed(increment)(i) for i in data]

# Агрегация слоя 1 (сумма)
total1 = delayed(sum)(layer1)
# total1.visualize() # Можно раскомментировать для проверки

def double(x):
    return x * 2

# Слой 2: Удвоение результатов из слоя 1 (пример логики, 
# здесь можно использовать output предыдущего шага или строить новую цепочку)
# В примере из методички строится цепочка:
layer2 = [delayed(double)(j) for j in layer1]
total2 = delayed(sum)(layer2)

# Визуализация полного графа
total2.visualize()

# Вычисление
result = total2.compute()
print("Результат:", result)
```

Также попробуйте визуализировать граф реальной задачи из пункта 4.1:
```python
# Визуализация графа подсчета пропусков из первой части
missing_count.visualize()
```

---

## Варианты индивидуальных заданий

**Источник данных:** [Скачать датасеты (Яндекс.Диск)](https://disk.yandex.ru/d/fbPE3VNKYocd7g).

Необходимо выбрать файл согласно вашему номеру в списке группы. Если датасет в архиве (`.zip`), его необходимо распаковать перед загрузкой.

| Вариант | Файл датасета | Описание |
| :---: | :--- | :--- |
| **1** | `Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv` | Штрафы за парковку (NY), 2014 |
| **2** | `Parking_Violations_Issued_-_Fiscal_Year_2015.csv` | Штрафы за парковку (NY), 2015 |
| **3** | `Parking_Violations_Issued_-_Fiscal_Year_2016.csv` | Штрафы за парковку (NY), 2016 |
| **4** | `Parking_Violations_Issued_-_Fiscal_Year_2017.csv` | Штрафы за парковку (NY), 2017 |
| **5** | `UK Property Price official data 1995-202304.zip` | Цены на недвижимость в UK |
| **6** | `Austin, TX House Listings.zip` | Объявления о продаже домов, Остин |
| **7** | `Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv` | Повтор варианта 1 |
| **8** | `Parking_Violations_Issued_-_Fiscal_Year_2015.csv` | Повтор варианта 2 |
| **9** | `Parking_Violations_Issued_-_Fiscal_Year_2016.csv` | Повтор варианта 3 |
| **10** | `Parking_Violations_Issued_-_Fiscal_Year_2017.csv` | Повтор варианта 4 |
| **11** | `UK Property Price official data 1995-202304.zip` | Повтор варианта 5 |
| **12** | `Austin, TX House Listings.zip` | Повтор варианта 6 |
| **13** | `Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv` | Повтор варианта 1 |
| **14** | `Parking_Violations_Issued_-_Fiscal_Year_2015.csv` | Повтор варианта 2 |
| **15** | `Parking_Violations_Issued_-_Fiscal_Year_2016.csv` | Повтор варианта 3 |
| **16** | `Parking_Violations_Issued_-_Fiscal_Year_2017.csv` | Повтор варианта 4 |
| **17** | `UK Property Price official data 1995-202304.zip` | Повтор варианта 5 |
| **18** | `Austin, TX House Listings.zip` | Повтор варианта 6 |
| **19** | `Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv` | Повтор варианта 1 |
| **20** | `Parking_Violations_Issued_-_Fiscal_Year_2015.csv` | Повтор варианта 2 |
| **21** | `Parking_Violations_Issued_-_Fiscal_Year_2016.csv` | Повтор варианта 3 |
| **22** | `Parking_Violations_Issued_-_Fiscal_Year_2017.csv` | Повтор варианта 4 |
| **23** | `UK Property Price official data 1995-202304.zip` | Повтор варианта 5 |
| **24** | `Austin, TX House Listings.zip` | Повтор варианта 6 |
| **25** | `Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv` | Повтор варианта 1 |

---

## Требования к отчетности и критерии оценки

Отчет сдается в виде ссылки на репозиторий GitHub/GitVerse, содержащий выполненный `.ipynb` файл с сохраненными выводами (output) ячеек.

### Критерии оценки (Максимум 10 баллов)

| Критерий | Баллы | Описание |
|---|---|---|
| **Настройка среды** | 1 | Корректная установка библиотек, подключение Google Drive (при необходимости), импорт модулей. |
| **Загрузка и анализ (4.1.2 - 4.1.3)** | 3 | Данные успешно загружены через Dask. Проведен анализ пропусков, использован `ProgressBar`, получены корректные проценты пропусков. |
| **Очистка данных (4.1.4)** | 2 | Реализована логика удаления столбцов с большим количеством пропусков. Показан результат (head) очищенного датафрейма. |
| **Визуализация DAG (4.2)** | 3 | Построены и визуализированы графы для простых и сложных зависимостей. Картинки графов отображаются в ноутбуке. |
| **Оформление** | 1 | Ноутбук структурирован, код читаем, название файла соответствует требованиям (`lab_04_variant_XX.ipynb`). |

### Контрольные вопросы
1. В чем главное отличие `dask.dataframe` от `pandas.dataframe`?
2. Что такое "ленивые вычисления" (lazy evaluation) и какой метод инициирует реальный расчет в Dask?
3. Что такое DAG (Directed Acyclic Graph) и зачем он нужен планировщику задач?
```