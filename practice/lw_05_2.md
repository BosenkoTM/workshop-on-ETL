# Лабораторная работа №5.2. Разработка алгоритмов для трансформации данных. Бизнес-кейс «Rocket»

**Цель работы:**
-  Закрепить навыки развертывания Apache Airflow в контейнеризированной среде (Docker).
-  Изучить работу с JSON-данными и бинарным контентом (изображениями) внутри ETL-процесса.
-  Научиться проектировать архитектуру ETL-решений и визуализировать её.
-  Автоматизировать выгрузку результатов работы DAG из контейнера в хост-систему.

**Репозиторий проекта:** `https://github.com/BosenkoTM/workshop-on-ETL/tree/main/business_case_rocket_25`

---

## 1. Подготовка окружения

### 1.1. Развертывание ВМ
-  Скачайте образ виртуальной машины `ETL+devops_26.ova`
-  В VirtualBox выберите **File -> Import Appliance**.
-  Выберите скачанный файл и следуйте инструкциям.
-  Запустите виртуальную машину.

### 1.2. Настройка проекта
-  В терминале ВМ клонируйте репозиторий:
    ```bash
    git clone https://github.com/BosenkoTM/workshop-on-ETL.git
    ```
-  Перейдите в директорию кейса:
    ```bash
    cd workshop-on-ETL/business_case_rocket_25
    ```

### 1.3. Запуск Airflow в Docker
-  Соберите Docker-образ (убедитесь, что находитесь в папке с `Dockerfile`):
    ```bash
    sudo docker build -t custom-airflow:slim-2.8.1-python3.11 .
    ```
-  Запустите сервисы:
    ```bash
    sudo docker compose up --build
    ```
    *(При необходимости полной очистки перед запуском используйте: `sudo docker system prune -a --volumes -f`)*

-  После успешного запуска перейдите в браузере по адресу: `http://localhost:8080/`.
-  Для остановки работы используйте:
    ```bash
    sudo docker compose down
    ```

---

## 2. Ход работы

### 2.1. Проектирование архитектуры (Draw.io)
Используя сервис [draw.io](https://app.diagrams.net/), создайте две схемы:

1.  **Верхнеуровневая архитектура аналитического решения:**
    *   *Source Layer.* Источники данных (Launch Library 2 API, JSON файлы).
    *   *Storage Layer.* Где хранятся скачанные изображения и обработанные данные (Docker Volume, локальная папка, БД).
    *   *Business Layer.* Как пользователь получает доступ к данным (отчеты, выгруженные файлы).
2.  **Архитектура DAG «Rocket»:**
    *   Визуализируйте логику работы вашего пайплайна (Start -> Download Data -> Parse JSON -> Download Images -> Notification -> End).

### 2.2. Реализация DAG и Индивидуальные задания
Разработайте или модифицируйте файл DAG (назовите его `listing_fio_Rocket.py`), реализовав функционал согласно вашему варианту (см. раздел 4).

### 2.3. Скрипт автоматизации (Bash)
**Общее задание.** Создайте исполняемый файл `export_data.sh`, который автоматизирует выгрузку данных (изображений/отчетов) из Docker-контейнера в основную ОС.
*Подсказка: используйте команду `docker cp`.*

### 2.4. Анализ выполнения
-  Запустите ваш DAG в Airflow.
-  Дождитесь успешного выполнения (зеленый статус).
-  Сделайте скриншот **Gantt Chart** (диаграммы Ганта) выполнения задач.
-  Сделайте скриншот логов ключевой задачи (например, скачивания изображений).

---

## 3. Требования к отчету

Все результаты работы необходимо разместить в публичном Git-репозитории (GitHub, GitLab или GitVerse). На учебный портал предоставляется **только ссылка** на этот репозиторий.

**В репозитории должны быть размещены:**
-  Файл отчета `ФИО-Rocket.pdf`.
-  Файл DAG `listing_fio_Rocket.py`.
-  Скрипт выгрузки `export_data.sh`.

**Структура отчета (`ФИО-Rocket.pdf`):**
-  **Постановка задачи.** Описание цели и вашего варианта.
-  **Архитектура:**
    *   Схема верхнеуровневого решения (draw.io).
    *   Схема архитектуры DAG (draw.io).
-  **Реализация:**
    *   Исходный код DAG (вставка кода или ссылка на файл в репозитории).
    *   Исходный код скрипта выгрузки (вставка кода или ссылка на файл в репозитории).
-  **Результаты:**
    *   Скриншот графа DAG (Graph View) из Airflow.
    *   Скриншот диаграммы Ганта.
    *   Скриншот лог-файла (Logs) успешного выполнения.
-  **Выводы.**

---

## 4. Индивидуальные задания

| Вариант | Задание 1 (Анализ/ETL) | Задание 2 (Обработка/Логика) | Задание 3 (Отчетность/Метрики) |
|:---:|---|---|---|
| 1 | Анализ данных JSON: отчет о кол-ве запусков за последний месяц | Обработка исключений для недоступных полей JSON | Отчет: кол-во успешно скачанных изображений с URL |
| 2 | Изучить структуру JSON запуска ракет | Уведомления (print/email) при ошибке скачивания | Настроить DAG на ежедневный запуск |
| 3 | Сценарий автозагрузки изображений | Модель/скрипт подсчета изображений за 30 дней | Отчет: какие изображения не удалось скачать |
| 4 | Таблица с ключевыми метками запуска из JSON | Автоматизация извлечения данных для графиков | Анализ ошибок при скачивании (лог) |
| 5 | Изучить архитектуру Airflow (описать в отчете) | Мониторинг ошибок скачивания | Анализ эффективности загрузки (время/объем) |
| 6 | Автоматическая обработка данных запуска | Уведомления при сбоях загрузки | Анализ частоты запусков за месяц |
| 7 | Отчет по скачиванию изображений (из JSON) | Обосновать выбор BashOperator vs PythonOperator | Изучить альтернативные API ракет |
| 8 | Анализ структуры JSON для улучшений | DAG для скачивания данных по историческим ракетам | Оценка ошибок JSON и предложения исправлений |
| 9 | Агрегация всех изображений в одну папку | Обработка недоступных изображений (отдельный список) | Уведомление по завершении всех процессов |
| 10 | Логирование процесса загрузки изображений | Метрики скорости загрузки изображений | Отчет по времени отклика для каждого URL |
| 11 | Проверка доступности URL перед скачиванием | Оценка производительности на больших данных | План улучшения скорости скачивания |
| 12 | Отчет по незагруженным изображениям | Мониторинг успешных запусков (Success/Fail callback) | Анализ уязвимостей реализации DAG |
| 13 | Отчет. Список ракет и их изображений | Загрузка с альтернативных источников (mock) | Анализ типов исключений (HTTP errors) |
| 14 | Таблица этапов загрузки (Markdown/CSV) | Обход ошибок подключения (Retries) | Настроить параметры `retries` в Airflow |
| 15 | DAG для еженедельного скачивания | Анализ процесса подключения | Обработка случая "нет изображений" |
| 16 | Отчет. Число скачанных с конкретных доменов | Проверка доступности серверов (Ping/Head) | Логирование ошибок для будущего анализа |
| 17 | Отчет. Число изображений по каждому запуску | Анализ успешности операций (процент успеха) | Автооповещение (Log/Email) при завершении |
| 18 | Отчет. Кол-во изображений на запуск | Циклическая обработка новых данных | Оценка потребности в доп. данных |
| 19 | Анализ расширения DAG (новые типы данных) | Оптимизация хранения (сжатие/структура папок) | Возможность выполнения на удаленных воркерах |
| 20 | Проверка целостности изображений (размер > 0) | Анализ возможностей ускорения (Parallelism) | Отчет по времени выполнения задач (Duration) |
| 21 | Уведомления о статусе каждого изображения | Обработка данных с разных серверов | Сравнение BashOperator и PythonOperator |
| 22 | Контроль дубликатов (не качать повторно) | Отчет по частоте ошибок загрузки | Мониторинг успешных запусков |
| 23 | Изучить структуру DAG для изображений | Уведомление, если изображений не найдено | Оптимизация времени выполнения задач |
| 24 | Работа с несколькими API (теоретически или mock) | Улучшение структуры JSON для точности | Одновременная обработка нескольких URL (Concurrency) |
| 25 | Управление большим кол-вом изображений | Отчетность по процессам скачивания | Предупреждения (Warnings) при ошибках загрузки |
| 26 | Анализ кол-ва изображений по типам ракет | Отчет по неудачным попыткам | Механизм исправления ошибок кода (предложения) |
| 27 | Мониторинг регулярных обновлений данных | Анализ задержек (API vs DAG run time) | Методы улучшения синхронизации |
| 28 | Отчет. Успешные загрузки + время выполнения | Зависимость кол-ва изображений от частоты запуска | Предложения по улучшению процесса |
| 29 | Отчет. Популярные ракеты (по частоте фото) | Архивирование изображений (zip) | Авто-перескачивание неудачных (Logic in DAG) |
| 30 | Обработка часовых поясов запусков | Анализ временных задержек скачивания | Оптимизация для ограниченной сети |

---

## 5. Критерии оценки (Максимум 10 баллов)

| Критерий | Баллы | Описание |
|---|---|---|
| **Развертывание и настройка** | 1 | Airflow успешно запущен в Docker, репозиторий клонирован. |
| **Архитектура (Draw.io)** | 2 | Представлены две корректные схемы: общая архитектура решения и архитектура конкретного DAG. Соблюдена слойность (Source/Storage/Business). |
| **Реализация DAG (Python)** | 4 | DAG `listing_fio_Rocket.py` запускается без ошибок. Реализованы все пункты индивидуального задания (логика, обработка ошибок, отчетность). |
| **Скрипт выгрузки (.sh)** | 1 | Написан и работает Bash-скрипт для копирования данных из контейнера на хост. |
| **Отчет и мониторинг** | 2 | Отчет содержит диаграмму Ганта, логи выполнения, описание постановки задачи и выводы. |

---

## 6. Устранение неполадок (Занят порт 8080)

Если при запуске возникает ошибка `Bind for 0.0.0.0:8080 failed: port is already allocated`:

  Остановите текущие контейнеры:
  
    ```bash
    sudo docker stop $(sudo docker ps -q)
    ```
  Если не помогло, удалите их:
  
    ```bash
    sudo docker rm $(sudo docker ps -a -q)
    ```
  Перезапустите службу Docker:
  
    ```bash
    sudo systemctl restart docker
    ```
  Проверьте порт:
  
    ```bash
    sudo lsof -i :8080
    ```
  Повторите запуск:
  
    ```bash
    sudo docker compose up --build
    ```

```

