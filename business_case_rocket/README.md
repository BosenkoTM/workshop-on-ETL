# Бизнес-кейс «Rocket»

Самостоятельная работа

5.1.1. Развернуть ВМ [ubuntu_mgpu.ova](https://disk.yandex.ru/d/Psofa9xtbgUEOw) в [VirtualBox](https://disk.yandex.ru/d/3fD00plnL_a4Cw).

5.1.2. Клонировать на ПК задание **Бизнес-кейс «Rocket»** в домашний каталог ВМ. 

`git clone https://github.com/BosenkoTM/workshop-on-ETL.git`

5.1.3. Запустить контейнер с кейсом, изучить  основные элементы `DAG` в `Apache Airflow`. 
   - Создать `DAG` согласно алгоритму, который предоставит преподаватель.
   - Изучить логи, выполненного DAG. Скачать логи из контейнера на основную ОС, используя команду:

```bash
docker cp <container_hash>:/path/to/zip/file.zip /path/on/host/new_name.zip
```
   - Выгрузить полученный результат работы `DAG` в основной каталог ОС, используя команду:

```bash
docker cp -r <containerId>:/path/to/directory /path/on/host 
```
**5.1.4.** Создать исполняемый файл с расширением `.sh`, который автоматизирует выгрузку данных из контейнера в основную ОС данных, полученные в результате работы `DAG` в `Apache Airflow`. 

5.1.5. Спроектировать верхнеуровневую архитектуру аналитического решения задания **Бизнес-кейса «Rocket»** в `draw.io`. Необходимо использовать:
   - `Source Layer` - слой источников данных.
   - `Storage Layer` - слой хранения данных.
   - `Business Layer` - слой для доступа к данным пользователей.

5.1.6. Спроектировать архитектуру `DAG` **Бизнес-кейса «Rocket»** в `draw.io`. Необходимо использовать:
   - `Source Layer` - слой источников данных.
   - `Storage Layer` - слой хранения данных.
   - `Business Layer` - слой для доступа к данным пользователей.

5.1.7. Построить диаграмму Ганта работы `DAG` в `Apache Airflow`.

5.1.8. Результаты исследований представить в виде файла `ФИО-05.pdf`, в котором отражены следующие результаты:
- постановка задачи;
- исходный код всех DAGs, которые требовались для решения задачи, а также представить граф `DAG` в `Apache Airflow`;
- верхнеуровневая архитектура задания **Бизнес-кейса «Rocket»**, выполненная в `draw.io`;
- архитектура `DAG` **Бизнес-кейса «Rocket»** , выполненная в `draw.io`;
- скрин лог-файла результаов работы `DAGs` в `Apache Airflow`;
- диаграмма Ганта `DAG` в `Apache Airflow`.

После проверки преподавателем работоспособности `DAG`, выгрузить отчет на портал [moodle](http://95.131.149.21/moodle/mod/assign/view.php?id=747).

Конечный `DAG` для тестирования - `listing_2_10.py`.

## Использование

Чтобы начать работу с примерами кода, запустите Airflow в докере, используя следующую команду:
1. Собираем Docker-образ из текущей директории (.) и присваивает ему тег `custom-airflow:slim-2.8.1-python3.11`.
   ```bash
   sudo docker build -t custom-airflow:slim-2.8.1-python3.11 .
   ```
2. Собираем (если нужно) и запускает все сервисы, описанные в `docker-compose.yml`.
   ```bash
   sudo docker compose up --build
   ```
3. Если требуется полностью пересобрать образ и запустить по новому контейнеры с сетью
   ```bash
   sudo docker system prune -a --volumes -f
    ```
4. Для работы с `DAG` перейти по линку `http://localhost:8080/`.

   Чтобы остановить выполнение примеров, выполните следующую команду:

    ```
    sudo docker compose down
    ```

## Индивидуальные задания


| Вариант | Задание 1 | Задание 2 | Задание 3 |
|---------|-----------|-----------|-----------|
| 1       | Анализировать данные о стартах ракет из JSON-файла и составить отчет о количестве запусков за последний месяц | Разработать способ обработки исключений для недоступных данных в JSON | Создать отчет по количеству успешно скачанных изображений с URL |
| 2       | Изучить структуру JSON, используемого для загрузки данных о стартах ракет | Разработать метод уведомлений при ошибке в скачивании изображений | Настроить DAG для обработки данных о стартах ракет с ежедневным запуском |
| 3       | Подготовить сценарий для автоматической загрузки и сохранения изображений ракет | Создать модель для подсчета изображений, загруженных за последние 30 дней | Разработать отчет о том, какие изображения не удалось скачать |
| 4       | Построить таблицу с ключевыми метками данных о запуске ракет из JSON | Автоматизировать процесс извлечения данных для визуализации на графиках | Создать отчет с анализом ошибок при скачивании изображений |
| 5       | Изучить архитектуру системы Airflow для обработки данных с использованием DAG | Настроить мониторинг ошибок в процессе скачивания изображений | Создать документ с анализом эффективности загрузки данных о стартах ракет |
| 6       | Настроить Airflow для автоматической обработки данных по запуску ракет | Реализовать систему уведомлений при сбоях загрузки изображений | Провести анализ на количество и частоту запусков ракет за последний месяц |
| 7       | Создать отчет по скачиванию изображений на основе данных JSON | Оценить необходимость использования BashOperator и PythonOperator для таких задач | Изучить альтернативы для получения данных о стартах ракет с использованием API |
| 8       | Проанализировать структуру данных о запуске ракет для возможных улучшений | Создать DAG для скачивания данных по старым ракетам | Оценить возможные ошибки в структуре данных JSON и предложить их исправление |
| 9       | Разработать решение для агрегации всех изображений в одну папку | Настроить обработку недоступных изображений в отдельный отчет | Разработать систему уведомлений по завершении всех процессов в DAG |
| 10      | Настроить файл логирования для загрузки изображений в процессе работы DAG | Разработать возможность получения метрик по скорости загрузки изображений | Создать отчеты по времени отклика для каждого изображения |
| 11      | Разработать метод анализа доступности изображений на сервере по URL | Оценить производительность текущего кода на больших объемах данных | Создать план по улучшению скорости скачивания изображений с учетом возможных ошибок |
| 12      | Настроить отчеты по изображениям, которые не удалось скачать | Разработать систему мониторинга успешных запусков DAG | Проанализировать возможные уязвимости в текущей реализации DAG |
| 13      | Создать отчет по списку ракет и их изображений, используя данные JSON | Настроить загрузку изображений с альтернативных источников | Проанализировать, какие типы исключений нужно обрабатывать для успешной загрузки |
| 14      | Построить в таблице GitHub все этапы процесса загрузки данных и изображений | Разработать методику для обхода ошибок подключения к серверу для скачивания изображений | Настроить повторные попытки скачивания изображений с использованием Airflow |
| 15      | Настроить DAG для еженедельного скачивания новых изображений ракет | Проанализировать процесс подключения к серверу для получения изображений | Разработать автоматическую обработку ошибок при отсутствии изображений |
| 16      | Создать отчет по числу скачанных изображений с конкретных URL | Настроить систему проверки доступности серверов для скачивания изображений | Разработать систему логирования ошибок для анализа на будущее |
| 17      | Разработать отчет по числу скачанных изображений по каждому запуску ракеты | Настроить автоматический анализ успешности выполнения операций скачивания | Разработать систему автооповещений по завершению операций в DAG |
| 18      | Построить отчет по количеству скачанных изображений по каждому запуску ракеты | Настроить DAG для циклической обработки новых данных о стартах ракет | Оценить потребности в дополнительных данных для более точных отчетов |
| 19      | Проанализировать возможности расширения DAG для поддержки других типов данных | Разработать систему загрузки и хранения изображений ракет с улучшением производительности | Настроить использование Airflow для выполнения процессов на других серверах |
| 20      | Разработать процедуру для проверки целостности изображений после их скачивания | Проанализировать дополнительные возможности для ускорения работы DAG | Создать систему отчетности по времени выполнения задач в DAG |
| 21      | Создать структуру уведомлений о статусе каждого изображения | Разработать систему для обработки данных с разных серверов с различной скоростью | Оценить работу BashOperator и PythonOperator для обработки данных |
| 22      | Построить систему контроля для предотвращения скачивания одинаковых изображений | Создать отчет по частоте ошибок в процессе загрузки изображений | Настроить мониторинг успешных запусков DAG |
| 23      | Изучить структуру DAG для автоматической работы с изображениями ракет | Разработать способ уведомления при отсутствии изображений в результатах запуска | Оценить время выполнения каждой задачи в DAG и предложить оптимизации |
| 24      | Настроить DAG для работы с изображениями по нескольким API для разных типов ракет | Проанализировать возможные улучшения в структуре данных JSON для повышения точности | Настроить DAG для одновременной обработки нескольких URL |
| 25      | Создать метод для управления большим количеством скачанных изображений | Настроить систему для отчетности по процессам скачивания | Разработать систему предупреждений для ошибок загрузки изображений |
| 26      | Проанализировать количество изображений для каждого типа ракеты в JSON | Разработать структуру для отчета по неудачным попыткам скачивания | Разработать механизм для анализа и исправления ошибок в коде загрузки изображений |
| 27      | Настроить мониторинг запуска DAG для регулярных обновлений данных о стартах ракет | Проанализировать временные интервалы между запуском DAG и обновлением данных | Разработать методы для улучшения синхронизации данных с API |
| 28      | Разработать отчет по успешным загрузкам изображений с указанием времени выполнения | Проанализировать зависимость количества скачанных изображений от частоты запусков DAG | Создать документ с предложениями по улучшению структуры процесса в DAG |
| 29      | Построить отчеты по наиболее популярным изображениям ракет по частоте их скачивания | Разработать систему архивирования изображений для долгосрочного хранения | Настроить систему для автоматического перескачивания неудачных изображений |
| 30      | Настроить DAG для обработки данных по запуску ракет в разных часовых поясах | Проанализировать временные задержки в процессе скачивания изображений | Разработать систему для оптимизации процессов скачивания изображений в условиях ограниченной пропускной способности |


## Занят порт

Это может быть связано с тем, что контейнеры, даже после перезапуска Docker, продолжают автоматически запускаться.

Чтобы решить эту проблему, выполните следующие шаги:

1. Остановить все контейнеры Docker.
   
Убедитесь, что все контейнеры остановлены. Вы можете остановить их с помощью команды:

```bash
sudo docker stop $(sudo docker ps -q)
```

2. Удалить все контейнеры.
3. 
Если контейнеры все равно остаются активными или вы хотите их полностью удалить, используйте команду:

```bash
sudo docker rm $(sudo docker ps -a -q)
```

3. Перезапустить Docker.
4. 
После остановки и удаления всех контейнеров снова перезапустите Docker:

```bash
sudo systemctl restart docker
```

4. Проверить использование порта 8080.
Теперь выполните команду, чтобы убедиться, что порт 8080 не занят:

```bash
sudo lsof -i :8080
```

Если порт не занят, вы можете продолжить запуск Docker Compose.

5. Запуск Docker Compose.
Если порт больше не занят, запустите контейнеры с помощью Docker Compose:

```bash
sudo docker-compose up --build
```


